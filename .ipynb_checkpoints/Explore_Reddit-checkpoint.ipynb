{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "import requests \n",
    "import json\n",
    "from datetime import date\n",
    "import csv\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "from time import mktime\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def getPushshiftData(query, after, before, sub):\n",
    "def getPushshiftData(after, before, sub):\n",
    "    #url = 'https://api.pushshift.io/reddit/search/submission/?title='+str(query)+'&size=1000&after='+str(after)+'&before='+str(before)+'&subreddit='+str(sub)\n",
    "    url = 'https://api.pushshift.io/reddit/search/submission/?size=1000&after='+str(after)+'&before='+str(before)+'&subreddit='+str(sub)\n",
    "    #url = 'https://api.pushshift.io/reddit/search/submission/?link_flair_text=Resources&size=1000&after='+str(after)+'&before='+str(before)+'&subreddit='+str(sub)\n",
    "    #SEE ABOUT SOME OTHER THING FOR FLAIR doesn't seem to be working\n",
    "    print(url)\n",
    "    r = requests.get(url)\n",
    "    data = json.loads(r.text)\n",
    "    return data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def collectSubData(subm):\n",
    "#     subData = list() #list to store data points\n",
    "#     title = subm['title']\n",
    "#     url = subm['url']\n",
    "#     try:\n",
    "#         flair = subm['link_flair_text']\n",
    "#     except KeyError:\n",
    "#         flair = \"NaN\"  \n",
    "#     try:\n",
    "#         flair_acss = subm['author_flair_css_class']\n",
    "#     except KeyError:\n",
    "#         flair_acss = \"NaN\"\n",
    "#     try:\n",
    "#         flair_atext = subm['author_flair_text']\n",
    "#     except KeyError:\n",
    "#         flair_atext = \"NaN\"\n",
    "#     try:\n",
    "#         flair_lcss = subm['link_flair_css_class']\n",
    "#     except KeyError:\n",
    "#         flair_lcss = \"NaN\"\n",
    "#     author = subm['author']\n",
    "#     sub_id = subm['id']\n",
    "#     score = subm['score']\n",
    "#     created = datetime.fromtimestamp(subm['created_utc']) #1520561700.0\n",
    "#     numComms = subm['num_comments']\n",
    "#     permalink = subm['permalink']\n",
    "    \n",
    "    #instead of appending all to subData like this, have to change it so each data type appends to its own thing we can \n",
    "    #just use as a column. Then you can put them all in a list named data if you want\n",
    "    #but theeeen we'd have to pass every list into this and return all of them\n",
    "#     subData.append((sub_id,title,url,author,score,created,numComms,permalink,flair,flair_acss,flair_atext,flair_lcss))\n",
    "#     subStats[sub_id] = subData\n",
    "    \n",
    "    #print(subStats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectSubData(subm):\n",
    "    id.append(subm['id'])\n",
    "    title.append(subm['title'])\n",
    "    url.append(subm['url'])\n",
    "    try:\n",
    "        flair.append(subm['link_flair_text'])\n",
    "    except KeyError:\n",
    "        flair.append(\"NaN\")\n",
    "    author.append(subm['author'])\n",
    "    created.append(datetime.fromtimestamp(subm['created_utc'])) #1520561700.0\n",
    "    numComms.append(subm['num_comments'])\n",
    "    permalink.append(subm['permalink'])\n",
    "    try:\n",
    "        selftext.append(subm['selftext'])\n",
    "    except KeyError:\n",
    "        selftext.append(\"NaN\")\n",
    "    \n",
    "#     print(subm['selftext'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subreddit to query\n",
    "#sub='PS4'\n",
    "sub='COVID19_support'\n",
    "#before and after dates\n",
    "#before = \"1538352000\" #October 1st\n",
    "#after = \"1514764800\"  #January 1st \n",
    "# before = \"1585699200\"\n",
    "# after = \"1580515200\"\n",
    "before = \"2020-05-15\" \n",
    "after = \"2020-05-14\"  \n",
    "#query = \"Screenshot\"\n",
    "# subCount = 0\n",
    "# subStats = {}\n",
    "\n",
    "#add whatever data you want below, adjust range to match number of columns and give them their title in subredditdata\n",
    "# id, title, url, author, created, numComms, permalink, flair = ([] for i in range(8))\n",
    "# subredditdata = {\"sub id\": id, \"title\": title, \"url\": url, \"author\": author, \"created\": created, \"numComms\": numComms,\n",
    "#                  \"permalink\": permalink, \"flair\": flair}\n",
    "\n",
    "title, selftext, permalink, author, created = ([] for i in range(5)) #find out the parameter for the actual post text\n",
    "subredditdata = {\"author username\": author, \"title\": title, \"text body\": selftext, \"date created\": created, \"permalink\": permalink}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=2020-05-14&before=2020-05-15&subreddit=COVID19_support\n",
      "28\n",
      "2020-05-14 19:45:38\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1589499938&before=2020-05-15&subreddit=COVID19_support\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#data = getPushshiftData(query, after, before, sub)# Will run until all posts have been gathered \n",
    "data = getPushshiftData(after, before, sub)\n",
    "# from the 'after' date up until before date\n",
    "while len(data) > 0:\n",
    "    for submission in data:\n",
    "        collectSubData(submission)\n",
    "        subCount+=1\n",
    "    # Calls getPushshiftData() with the created date of the last submission\n",
    "    print(len(data))\n",
    "    print(str(datetime.fromtimestamp(data[-1]['created_utc'])))\n",
    "    after = data[-1]['created_utc']\n",
    "    data = getPushshiftData(after, before, sub)\n",
    "    #data = getPushshiftData(query, after, before, sub)\n",
    "    \n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(str(len(subStats)) + \" submissions have added to list\")\n",
    "# print(\"1st entry is:\")\n",
    "# print(list(subStats.values())[0][0][1] + \" created: \" + str(list(subStats.values())[0][0][5]))\n",
    "# print(\"Last entry is:\")\n",
    "# print(list(subStats.values())[-1][0][1] + \" created: \" + str(list(subStats.values())[-1][0][5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def updateSubs_file():\n",
    "#     upload_count = 0\n",
    "#     #location = \"\\\\Reddit Data\\\\\"\n",
    "    \n",
    "#     #print(\"input filename of submission file, please add .csv\")\n",
    "#     filename = \"redditdata.csv\"#input()\n",
    "#     #file = location + filename\n",
    "#     file = filename\n",
    "#     with open(file, 'w', newline='', encoding='utf-8') as file: \n",
    "#     # with open(file, 'w', newline='', encoding='utf-8') as file: \n",
    "#         a = csv.writer(file, delimiter=',')\n",
    "#         #headers = [\"Post ID\",\"Title\",\"Url\",\"Author\",\"Score\",\"Publish Date\",\"Total No. of Comments\",\"Permalink\",\"Flair\"]\n",
    "#         headers = [\"Post ID\",\"Title\",\"Url\",\"Author\",\"Score\",\"Publish Date\",\"Total No. of Comments\",\"Permalink\",\"Flair\",\"flair_acss\",\"flair_atext\",\"flair_lcss\"]\n",
    "#         a.writerow(headers)\n",
    "#         for sub in subStats:\n",
    "#             a.writerow(subStats[sub][0])\n",
    "#             upload_count+=1\n",
    "            \n",
    "#         print(str(upload_count) + \" submissions have been uploaded\") #updateSubs_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updateSubs_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subStats['f43bg7'][0][0]\n",
    "# subStats['f43bg7'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id = []\n",
    "# title = []\n",
    "# id, title = ([] for i in range(2))\n",
    "# for sub in subStats:\n",
    "# #     print(sub)\n",
    "#     id.append(subStats[sub][0][0])\n",
    "#     title.append(subStats[sub][0][1])\n",
    "\n",
    "# data = {'post id': id, 'title': title, }\n",
    "\n",
    "# print(subStats[sub][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author username</th>\n",
       "      <th>title</th>\n",
       "      <th>text body</th>\n",
       "      <th>date created</th>\n",
       "      <th>permalink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OTOT4</td>\n",
       "      <td>Exposure therapy for integrating back into the...</td>\n",
       "      <td>Hey all! I came across this page by accident a...</td>\n",
       "      <td>2020-05-13 20:23:02</td>\n",
       "      <td>/r/COVID19_support/comments/gjbfr3/exposure_th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lillybee1234</td>\n",
       "      <td>I did it, I went into a store</td>\n",
       "      <td>I posted a few days ago about how I couldn't e...</td>\n",
       "      <td>2020-05-13 20:56:59</td>\n",
       "      <td>/r/COVID19_support/comments/gjc0qb/i_did_it_i_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PlayfulTitan18</td>\n",
       "      <td>Hey everyone I thought I would give an update ...</td>\n",
       "      <td>So I made a post a while back about how this p...</td>\n",
       "      <td>2020-05-13 21:34:11</td>\n",
       "      <td>/r/COVID19_support/comments/gjcmkn/hey_everyon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Old_boy7</td>\n",
       "      <td>Anyone else have upset stomach as the primary ...</td>\n",
       "      <td>I should preference I never got tested. About ...</td>\n",
       "      <td>2020-05-13 21:45:50</td>\n",
       "      <td>/r/COVID19_support/comments/gjctdw/anyone_else...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rendervelvet</td>\n",
       "      <td>Navigating Extended Family and Social Distanci...</td>\n",
       "      <td>I (mid 30s) am currently sharing a household w...</td>\n",
       "      <td>2020-05-13 22:24:25</td>\n",
       "      <td>/r/COVID19_support/comments/gjdfb9/navigating_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  author username                                              title  \\\n",
       "0           OTOT4  Exposure therapy for integrating back into the...   \n",
       "1    lillybee1234                      I did it, I went into a store   \n",
       "2  PlayfulTitan18  Hey everyone I thought I would give an update ...   \n",
       "3        Old_boy7  Anyone else have upset stomach as the primary ...   \n",
       "4    rendervelvet  Navigating Extended Family and Social Distanci...   \n",
       "\n",
       "                                           text body        date created  \\\n",
       "0  Hey all! I came across this page by accident a... 2020-05-13 20:23:02   \n",
       "1  I posted a few days ago about how I couldn't e... 2020-05-13 20:56:59   \n",
       "2  So I made a post a while back about how this p... 2020-05-13 21:34:11   \n",
       "3  I should preference I never got tested. About ... 2020-05-13 21:45:50   \n",
       "4  I (mid 30s) am currently sharing a household w... 2020-05-13 22:24:25   \n",
       "\n",
       "                                           permalink  \n",
       "0  /r/COVID19_support/comments/gjbfr3/exposure_th...  \n",
       "1  /r/COVID19_support/comments/gjc0qb/i_did_it_i_...  \n",
       "2  /r/COVID19_support/comments/gjcmkn/hey_everyon...  \n",
       "3  /r/COVID19_support/comments/gjctdw/anyone_else...  \n",
       "4  /r/COVID19_support/comments/gjdfb9/navigating_...  "
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redditdata = pd.DataFrame(subredditdata)\n",
    "#redditdata.reset_index(drop = True)\n",
    "redditdata.head()\n",
    "# print(subredditdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-298-72c6d0b248ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# redditdata = redditdata.query(redditdata['text body'] == \"\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# redditdata = redditdata[redditdata['text body'] != (\"\" || \"[removed]\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mredditdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mredditdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mredditdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text body'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"[removed]\"\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mredditdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "# if text body - blank or [removed], drop row\n",
    "# redditdata = redditdata.query(redditdata['text body'] == \"\")\n",
    "# redditdata = redditdata[redditdata['text body'] != (\"\" || \"[removed]\")\n",
    "redditdata = redditdata[redditdata['text body'] != \"[removed]\"]\n",
    "redditdata = redditdata[redditdata['text body'] != \"\"]\n",
    "redditdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redditdata.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-PythonData] *",
   "language": "python",
   "name": "conda-env-.conda-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
